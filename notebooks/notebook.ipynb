{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "notebook",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "interpreter": {
      "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5WSKGgjo64g"
      },
      "source": [
        "!git clone https://github.com/khaykingleb/Automatic-Speech-Recognition.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m63VJGgLsfwM"
      },
      "source": [
        "!pip install -r ASR/requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4ClMevBsS6P"
      },
      "source": [
        "import sys\n",
        "sys.path.append('ASR/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyWYzDHb15vd"
      },
      "source": [
        "At first, I thought QuartzNet-15x5 would performe quite well on our data. But I overkilled the model with too agressive augmentation probrobabilities (it was 0.3 that some augmentation in sequence will be applied to data). After chagnging probabilities, I saw that the QuartzNet would require a [lot of time](https://wandb.ai/khaykingleb/asr_project/reports/Untitled-Report--VmlldzoxMTU0Mzg5) to train for near-SOTA results. Thus, due to time scarcity I decided to implement Deepspeech."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2KhMNZmJRhd"
      },
      "source": [
        "# Deepspeech"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufjhPMob2dl8"
      },
      "source": [
        "We will train the model in several steps.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TE6ptlsq2nEN"
      },
      "source": [
        "1) Train the Deepspeech on LJ-speech dataset for around 45 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1orXwLsQZyVn"
      },
      "source": [
        "%run ASR/train.py -c ASR/configs/deepspeech_ljspeech_config.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLyq3xU1zAS9"
      },
      "source": [
        "Achieved the 19 WER on this dataset. See the [report](https://wandb.ai/khaykingleb/asr_project/reports/Deepspeech-on-LJ-Dataset--VmlldzoxMTYyODk0?accessToken=z3uqf5tw1ank1nezv6wp2iyfgulhqxzfpt4utca5940te0l625rei54t1rxi0a1p)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTacs5BHNCXI"
      },
      "source": [
        "2) Fine-tune the Deepspeech on Librispeech clean dataset for around 35 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fAWU6EoHfLJ"
      },
      "source": [
        "!wget https://www.dropbox.com/s/3nznm2lwt58vzl0/deepspeech_ljspeech.pth?dl=0 \\\n",
        "    -P /trained_models \\\n",
        "    -O deepspeech_ljspeech.pth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCt7lL_T2cIk"
      },
      "source": [
        "%run ASR/train.py -c ASR/configs/deepspeech_librispeech_config.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1xSXP6O4NXx"
      },
      "source": [
        "It [can't train](https://wandb.ai/khaykingleb/asr_project/reports/Deepspeech-on-Librispeech-Dataset--VmlldzoxMTYzMDI4?accessToken=ds29hze7tlu15yowv7fywnxb06wqv6s7u8lz94g5xl5yqelp9a6wt5pxln710mmx), getting 18 CER, so we move on to the next dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuUOQ7zmOurV"
      },
      "source": [
        "3) Fine-tune the Deepspeech on Common Voice dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IADiqAlU8fg"
      },
      "source": [
        "!wget https://www.dropbox.com/s/3nznm2lwt58vzl0/deepspeech_librispeech.pth?dl=0 \\\n",
        "    -P /trained_models \\\n",
        "    -O deepspeech_librispeech.pth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_akgGE1O1hc"
      },
      "source": [
        "%run ASR/train.py -c ASR/configs/deepspeech_common_voice_config.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c53td8UyL_-q"
      },
      "source": [
        "I am currently at this stage. Dunno if i will make it to the end, but we will see.\n",
        "See the current [report](https://wandb.ai/khaykingleb/asr_project/reports/Deepspeech-on-Common-Voice-Dataset---VmlldzoxMTYyOTk3?accessToken=ud0553hxchj0qxr98bweqghsilt2o3torex7ra1f6gl0n6f46lqdtdnkfcivlbz7)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Io23H-pjPDBp"
      },
      "source": [
        "4) Fine-tune the Deepspeech on other Librispeech."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnZyo4TYPBqz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KYtWIMQMRav"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8-8Z_QZMVLW"
      },
      "source": [
        "Currently, I use model that is trained on first and second steps:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pddpk3b_Ozxz"
      },
      "source": [
        "!wget https://www.dropbox.com/s/154ajtbmo5bam19/checkpoint.pth?dl=0 \\\n",
        "    -P ASR/default_test_model/ \\\n",
        "    -O checkpoint.pth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4LTjDyQSouL"
      },
      "source": [
        "%run ASR/test.py \\\n",
        "   -c ASR/default_test_model/config.json \\\n",
        "   -r ASR/default_test_model/checkpoint.pth \\\n",
        "   -o ASR/default_test_model/result.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qXydnCOes71"
      },
      "source": [
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDWlLkpNxc1R"
      },
      "source": [
        "file = open('ASR/default_test_model/result.json')\n",
        "result = json.load(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nl3MqlkOyJWj"
      },
      "source": [
        "argmax_cer = 0\n",
        "argmax_wer = 0\n",
        "beam_search_cer = 0\n",
        "beam_search_wer = 0 \n",
        "\n",
        "for i in range(len(result)):\n",
        "    argmax_cer += result[i]['argmax_cer']\n",
        "    argmax_wer += result[i]['argmax_wer']\n",
        "    beam_search_cer += result[i]['beam_search_cer']\n",
        "    beam_search_wer += result[i]['beam_search_wer']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bd9KoyJtyT-U",
        "outputId": "a51219c0-b049-46ae-b0fe-acef9b87039f"
      },
      "source": [
        "print(f\"Argmax CER: {argmax_cer / len(result):.4}\")\n",
        "print(f\"Argmax WER: {argmax_wer / len(result):.4}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Argmax CER: 19.17\n",
            "Argmax WER: 53.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0zkTuS3xutc",
        "outputId": "0dc0cd11-d76f-42d8-f179-2d4a5ae39f9e"
      },
      "source": [
        "print(f\"Beam Search CER: {beam_search_cer / len(result):.4}\")\n",
        "print(f\"Beam Search WER: {beam_search_wer / len(result):.4}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beam Search CER: 20.44\n",
            "Beam Search WER: 56.92\n"
          ]
        }
      ]
    }
  ]
}